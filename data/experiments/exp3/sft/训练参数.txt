# ✅ 目标：更快 + 更省显存
# - cutoff_len=768：你的数据 99%<721 tokens，768 基本够用，显存/速度收益很大
# - num_train_epochs=1：只跑 1 个 epoch
# - 通过调大 batch、调小 accumulation 加速；保持有效 batch≈16（和你原来一致，训练更稳）
#   原来：bs=2, acc=8  => 有效batch=16
#   现在：bs=4, acc=4  => 有效batch=16（更快，显存略增但整体因 768 会更省）
# - save_steps 调大一点，减少频繁保存带来的 IO 开销（更快）

llamafactory-cli train \
  --stage sft \
  --do_train True \
  --model_name_or_path /mnt/systemDisk/model_cache/Qwen/Qwen2.5-7B-Instruct \
  --preprocessing_num_workers 16 \
  --finetuning_type lora \
  --template qwen \
  --flash_attn auto \
  --dataset_dir data \
  --dataset sft_law \
  --cutoff_len 768 \
  --learning_rate 1e-05 \
  --num_train_epochs 1.0 \
  --max_samples 100000 \
  --per_device_train_batch_size 4 \
  --gradient_accumulation_steps 4 \
  --lr_scheduler_type cosine \
  --max_grad_norm 1.0 \
  --logging_steps 10 \
  --save_steps 500 \
  --warmup_steps 0 \
  --packing False \
  --enable_thinking True \
  --report_to none \
  --output_dir saves/Qwen2.5-7B-Instruct/lora/train_fast_768_ep1 \
  --bf16 True \
  --plot_loss True \
  --trust_remote_code True \
  --ddp_timeout 180000000 \
  --include_num_input_tokens_seen True \
  --optim adamw_torch \
  --lora_rank 8 \
  --lora_alpha 16 \
  --lora_dropout 0 \
  --lora_target all
